{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f95cbff-4156-4842-ae9f-94de278300b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, col, lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cfab1-cce3-4279-8d2d-186f321090af",
   "metadata": {},
   "source": [
    "## Задача\n",
    "С помощью Spark разбейте названия фильмов на отдельные слова и посчитайте, какое слово встречается чаще всего."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c670be-0d90-4074-b5c9-068b416556c5",
   "metadata": {},
   "source": [
    "## Решение с помощью pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89667e25-5d71-4f57-88e0-6afd8336c2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Film\n",
       "the    14\n",
       "Name: Film, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movies.csv')\n",
    "(\n",
    "    df.Film\n",
    "    .apply(lambda x: x.split())\n",
    "    .explode()\n",
    "    .str.lower()\n",
    "    .to_frame()\n",
    "    .groupby('Film')['Film']\n",
    "    .count()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5cb9e-4654-4bb5-b38e-dcb444d1c492",
   "metadata": {},
   "source": [
    "## Решение с помощью spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fee7290-ad6c-4f93-98f0-a18b1a5f8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"hw_9_solution_khin\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21505248-d0e3-4fcf-a0a6-c97200189dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/08 02:05:21 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "25/01/08 02:05:21 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "25/01/08 02:05:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/01/08 02:05:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#75, None)) > 0)\n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 352.3 KiB, free 364.8 MiB)\n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 364.8 MiB)\n",
      "25/01/08 02:05:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:65226 (size: 34.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:05:21 INFO SparkContext: Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0\n",
      "25/01/08 02:05:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/01/08 02:05:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 13.5 KiB, free 364.7 MiB)\n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 364.7 MiB)\n",
      "25/01/08 02:05:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.10.2:65226 (size: 6.4 KiB, free: 366.1 MiB)\n",
      "25/01/08 02:05:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/08 02:05:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/01/08 02:05:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 9920 bytes) \n",
      "25/01/08 02:05:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "25/01/08 02:05:21 INFO FileScanRDD: Reading File path: file:///Users/khin/local/hse/1st_semester/python/hw_9/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "25/01/08 02:05:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1665 bytes result sent to driver\n",
      "25/01/08 02:05:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 8 ms on 172.20.10.2 (executor driver) (1/1)\n",
      "25/01/08 02:05:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/01/08 02:05:21 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.014 s\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/08 02:05:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/01/08 02:05:21 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.015275 s\n",
      "25/01/08 02:05:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/01/08 02:05:21 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 352.3 KiB, free 364.4 MiB)\n",
      "25/01/08 02:05:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 364.4 MiB)\n",
      "25/01/08 02:05:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.10.2:65226 (size: 34.9 KiB, free: 366.1 MiB)\n",
      "25/01/08 02:05:21 INFO SparkContext: Created broadcast 7 from csv at NativeMethodAccessorImpl.java:0\n",
      "25/01/08 02:05:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37cdacc2-5e87-449d-ae75-b7dffebcd3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------------+-------------+-----------------+---------------+----+\n",
      "|                Film|    Genre|         Lead Studio|Audience score %|Profitability|Rotten Tomatoes %|Worldwide Gross|Year|\n",
      "+--------------------+---------+--------------------+----------------+-------------+-----------------+---------------+----+\n",
      "|Zack and Miri Mak...|  Romance|The Weinstein Com...|              70|  1.747541667|               64|        $41.94 |2008|\n",
      "|     Youth in Revolt|   Comedy|The Weinstein Com...|              52|         1.09|               68|        $19.62 |2010|\n",
      "|You Will Meet a T...|   Comedy|         Independent|              35|  1.211818182|               43|        $26.66 |2010|\n",
      "|        When in Rome|   Comedy|              Disney|              44|            0|               15|        $43.04 |2010|\n",
      "|What Happens in V...|   Comedy|                 Fox|              72|  6.267647029|               28|       $219.37 |2008|\n",
      "| Water For Elephants|    Drama|    20th Century Fox|              72|  3.081421053|               60|       $117.09 |2011|\n",
      "|              WALL-E|Animation|              Disney|              89|  2.896019067|               96|       $521.28 |2008|\n",
      "|            Waitress|  Romance|         Independent|              67|   11.0897415|               89|        $22.18 |2007|\n",
      "| Waiting For Forever|  Romance|         Independent|              53|        0.005|                6|         $0.03 |2011|\n",
      "|     Valentine's Day|   Comedy|        Warner Bros.|              54|  4.184038462|               17|       $217.57 |2010|\n",
      "|Tyler Perry's Why...|  Romance|         Independent|              47|    3.7241924|               46|        $55.86 |2007|\n",
      "|Twilight: Breakin...|  Romance|         Independent|              68|  6.383363636|               26|       $702.17 |2011|\n",
      "|            Twilight|  Romance|              Summit|              82|  10.18002703|               49|       $376.66 |2008|\n",
      "|      The Ugly Truth|   Comedy|         Independent|              68|  5.402631579|               14|       $205.30 |2009|\n",
      "|The Twilight Saga...|    Drama|              Summit|              78|      14.1964|               27|       $709.82 |2009|\n",
      "|The Time Traveler...|    Drama|           Paramount|              65|  2.598205128|               38|       $101.33 |2009|\n",
      "|        The Proposal|   Comedy|              Disney|              74|       7.8675|               43|       $314.70 |2009|\n",
      "|The Invention of ...|   Comedy|        Warner Bros.|              47|  1.751351351|               56|        $32.40 |2009|\n",
      "|  The Heartbreak Kid|   Comedy|           Paramount|              41|  2.129444167|               30|       $127.77 |2007|\n",
      "|         The Duchess|    Drama|           Paramount|              68|  3.207850222|               60|        $43.31 |2008|\n",
      "+--------------------+---------+--------------------+----------------+-------------+-----------------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/08 02:07:40 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/01/08 02:07:40 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/01/08 02:07:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 352.2 KiB, free 365.1 MiB)\n",
      "25/01/08 02:07:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 365.1 MiB)\n",
      "25/01/08 02:07:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.10.2:65226 (size: 34.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:07:40 INFO SparkContext: Created broadcast 14 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/08 02:07:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/01/08 02:07:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Got job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/01/08 02:07:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 18.1 KiB, free 365.1 MiB)\n",
      "25/01/08 02:07:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 365.1 MiB)\n",
      "25/01/08 02:07:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.10.2:65226 (size: 8.0 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:07:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/08 02:07:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "25/01/08 02:07:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 9920 bytes) \n",
      "25/01/08 02:07:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "25/01/08 02:07:40 INFO FileScanRDD: Reading File path: file:///Users/khin/local/hse/1st_semester/python/hw_9/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "25/01/08 02:07:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3642 bytes result sent to driver\n",
      "25/01/08 02:07:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on 172.20.10.2 (executor driver) (1/1)\n",
      "25/01/08 02:07:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "25/01/08 02:07:40 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.012 s\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/08 02:07:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "25/01/08 02:07:40 INFO DAGScheduler: Job 6 finished: showString at NativeMethodAccessorImpl.java:0, took 0.013040 s\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "377ffc9b-66a6-4834-ba16-594db478ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/08 02:14:23 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/01/08 02:14:23 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 25.676417 ms\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 352.2 KiB, free 365.2 MiB)\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 365.1 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.10.2:65226 (size: 34.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO SparkContext: Created broadcast 22 from first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4\n",
      "25/01/08 02:14:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Registering RDD 55 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) as input to shuffle 0\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Got map stage job 10 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) with 1 output partitions\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4)\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[55] at first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4), which has no missing parents\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 42.1 KiB, free 365.1 MiB)\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 365.1 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.10.2:65226 (size: 19.8 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[55] at first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/08 02:14:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "25/01/08 02:14:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 9909 bytes) \n",
      "25/01/08 02:14:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 41.113375 ms\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 7.298791 ms\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 2.663125 ms\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 3.478667 ms\n",
      "25/01/08 02:14:23 INFO FileScanRDD: Reading File path: file:///Users/khin/local/hse/1st_semester/python/hw_9/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.10.2:65226 in memory (size: 34.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.10.2:65226 in memory (size: 34.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.10.2:65226 in memory (size: 7.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.10.2:65226 in memory (size: 7.9 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2820 bytes result sent to driver\n",
      "25/01/08 02:14:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 154 ms on 172.20.10.2 (executor driver) (1/1)\n",
      "25/01/08 02:14:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "25/01/08 02:14:23 INFO DAGScheduler: ShuffleMapStage 10 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) finished in 0.161 s\n",
      "25/01/08 02:14:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/01/08 02:14:23 INFO DAGScheduler: running: Set()\n",
      "25/01/08 02:14:23 INFO DAGScheduler: waiting: Set()\n",
      "25/01/08 02:14:23 INFO DAGScheduler: failed: Set()\n",
      "25/01/08 02:14:23 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 4.863375 ms\n",
      "25/01/08 02:14:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 5.532958 ms\n",
      "25/01/08 02:14:23 INFO SparkContext: Starting job: first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Got job 11 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) with 1 output partitions\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Final stage: ResultStage 12 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4)\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Missing parents: List()\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[59] at first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4), which has no missing parents\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 43.7 KiB, free 365.8 MiB)\n",
      "25/01/08 02:14:23 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 365.8 MiB)\n",
      "25/01/08 02:14:23 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.10.2:65226 (size: 20.8 KiB, free: 366.2 MiB)\n",
      "25/01/08 02:14:23 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[59] at first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) (first 15 tasks are for partitions Vector(0))\n",
      "25/01/08 02:14:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "25/01/08 02:14:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 9293 bytes) \n",
      "25/01/08 02:14:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 2.855041 ms\n",
      "25/01/08 02:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 (9.7 KiB) non-empty blocks including 1 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/01/08 02:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "25/01/08 02:14:23 INFO CodeGenerator: Code generated in 10.174459 ms\n",
      "25/01/08 02:14:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 5174 bytes result sent to driver\n",
      "25/01/08 02:14:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 59 ms on 172.20.10.2 (executor driver) (1/1)\n",
      "25/01/08 02:14:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "25/01/08 02:14:23 INFO DAGScheduler: ResultStage 12 (first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4) finished in 0.064 s\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/01/08 02:14:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "25/01/08 02:14:23 INFO DAGScheduler: Job 11 finished: first at /var/folders/8x/py78bv316g35sfyx4zxjd9vm0000gn/T/ipykernel_19413/2443885891.py:4, took 0.071099 s\n"
     ]
    }
   ],
   "source": [
    "words_df = df.select(explode(split(col(\"Film\"), \"\\\\s+\")).alias(\"word\"))\n",
    "words_df = words_df.withColumn(\"word\", lower(col(\"word\")))\n",
    "word_counts = words_df.groupBy(\"word\").count()\n",
    "most_common_word = word_counts.orderBy(col(\"count\").desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86a3b491-8fae-4206-ab51-2443e3cd21ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(word='the', count=14)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
